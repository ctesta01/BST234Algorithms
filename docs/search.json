[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Structures and Algorithms (BST 234) Notes",
    "section": "",
    "text": "Building 2, room 435\nResearch interests: algorithmic mathematics and statistics, efficient and randomized algorithms, methodology development, multiple testing, NP-complete problems.\nTA: Max Wang\nTake home midterm and final presentation project.\nWeek after of Spring Break is midterm."
  },
  {
    "objectID": "week1/week1.html",
    "href": "week1/week1.html",
    "title": "2  Week 1: Intro",
    "section": "",
    "text": "What is an algorithm?\n\nA (finite) sequence of instructions that transforms some (well-specified) input into (well-specified) output.\n\nDefinition from wikipedia:\n\nIn mathematics and computer science, an algorithm is an effective method expressed as a finite list of well-defined instructions for calculating a function.\n\nAlgorithm = “A tool for solving a well-defined computational problem”\nAlgorithm \\(f:\\) input \\(\\to\\) output.\nProperties?\n\nRun-time (time complexity)\nSpace complexity (how much disk space is taken up)\n\nSorting can be done in place\n\nDecideability\n\nWhen a computer gets to a step, it has to know what to do.\n\n\nOften time and space complexity play off each other.\nRhetorical appeal: just look on Instagram — we store so much stuff. Apparently space is cheap.\n1. do x \n   or do y \n\n# not an algorithm\n1. flip coin \n2. if heads -> x \n      tails -> y\n\n# is an algorithm\nRandomness comes in different flavors:\n\nQuicksort is a method that always sorts, but its run-time is random.\nMCMC uses randomness in the result, because if we run it twice the results are different.\n\nRuntime and correctness are the gold-standard in methodology development. Prove runtime, prove correctness in the p-sets.\nInput: a set of numbers \\(\\langle a_1, a_2, ..., a_n \\rangle\\).\nOutput: Sorted sequence of input data \\(\\langle a_1', a_2', ..., a_n' \\rangle\\) with \\(a_1' \\leq ... \\leq a_n'\\).\nA sorting algorithm \\(f\\) solves the problem defined by the input-output relationship.\nThere are many sorting techniques."
  },
  {
    "objectID": "index.html#goals-for-the-course",
    "href": "index.html#goals-for-the-course",
    "title": "Data Structures and Algorithms (BST 234) Notes",
    "section": "Goals for the course",
    "text": "Goals for the course\nIntroduction to important computational problems in computer science (biostatistics) and state of the art algorithms for solving them.\nUnderstanding of data structures and algorithms to solve problems of practical relevance.\nUnderstanding of mathematical standards for numerical analysis and statistics, inclusding their implementations.\nKnowledge of R and Python is vital (lab sessions).\nWhy is it always “Data Structures And Algorithms”?\nBecause the two are intrinsically linked; they don’t mean much without the other.\nWhy? Because the algorithm may run much faster or slower depending on the data structure.\nFor example, we might have a list. Or we might have a hash-map. Some things are fast in lists, whereas different things are fast in a hash-map.\nOften we have an end-pointer if we have a doubly-linked list.\nFor example, popping the first element, or last element, these are \\(O(1)\\) operations (including updating pointers). In contrast, searching is an \\(O(n)\\) operation when traversing.\nIf we have a binary tree (heap), then searching is \\(O(\\log_2 n )\\).\nWe will use the Cormen, Leiserson, Rivest, Stein. CLLS. Available for free on HOLLIS.\nContents\n\nIntroduction, random numbers\nConcepts of algorithms, complexity and sorting algorithms\nData structures and heapsort\nGreedy algorithms and dynamic programming\nIntroduction to parallel programming\nP and NP\nNumerical aspects of computer algorithms, condition of a problem, numerical stability of an algorithm, numerical error, forward/backward-error\nEfficient algorithms for linear algebra\nLeast-Squares Program, Eigenvalue Decomposition\nNumerical integration, Monte Carlo integration, importance sampling\nNumerical optimization\nWork on projects\nProject presentations"
  },
  {
    "objectID": "week1/week1.html#section",
    "href": "week1/week1.html#section",
    "title": "Week 1: Intro",
    "section": "",
    "text": "An iconic algorithm:\n\nfunction gcd(a,b): \n  while a ≠ b:\n    if a > b:\n      a := a-b\n    else: \n      b := b-a\n  return a\n\ngcd: 20, 15 -> 5 \n\na = 20, b = 15 \na = 5, b = 15, \na = 5, b = 1 \na = 5, b = 5\n\nThis algorithm is the greatest common divisor.\nThis is used in encryption and it is still the fastest algorithm.\nFrom ~300 BC from Euclid of Alexandria.\nExamples of algorithms:\n\nSorting Algorithms\nOptimization Problems:\n\nTraveling salesman: chip design, airline schedule\n\nMathematical problems:\n\nSolution of linear equations / matrix algebra\nIntegration\n\nStatistical problems\n\nOptimal designs / power calculations\nComputation of distributions\nComputation of test statistics\n\n\nExamples:\n\nEuclid GCD\nPagerank\nGradient descent\n\nLocal minimum\n\nBellman; Ford; shortest path and allow negative weights\nDjikstra\nCompression\nWord2Vec\nShannon Encoding for Transmission Errors\nTower of Hanoi\n\nRecursive\n\n\nGeorg’s hit-list:\n\nEuclid\nQuadratic Sieve\nBerlekamp\nCantor-Zassehaus\n\nFactoring numbers is super-polynomial but sub-exponential. It’s like almost exponential. This doesn’t go for factoring polynomials.\nWhen multiplying numbers, all the terms get jumbled up whereas we know where the pieces came from in polynomials:\n(123 * 827) = (1*10^2 + 2 * 10^2 + 3 * 10^0 ) * (...)\n\nvs. \n\n(2x + 3)(x^2 + 1)\n\nWhat do random numbers and compression have in common?\n\nProperties of Algorithms\n\nFeasibility\nTermination\nDeterministic\nFinite\n\nAlgorithms work on dynamic sets of elements (input -> output):\n\nSearching, inserting and deleting elements\nMaximum, minimum element\n\nData structures are used for the implementation of dynamic datasets. The efficiency of a data structure can depend on the desired manipulation operation.\nExamples of data structures:\n\nArray: access to elements based on index\n\nContinuous allocated memory, evenly divided\n\nLinked List: reference / pointer to the next element\nStack: dynamic set of elements, last in first out\nQueue: dynamic set of elements, can only be read starting from most longest added element, first-in-first-out\nGraphs or Trees: elements have references/pointers to a variable number of other elements\n\nCompare and contrast the array, doubly-linked list, and the heap:\n\n\n\n\n\n\n\nThe array has the property that if every element is of the same structure and takes up the same amount of memory, we can access the nth element quickly by calculating where it will be in memory and looking there. However, to update an array can be annoying because if it is growing and the neighboring memory is not free, we might have to move the whole array.\nThe doubly-linked list facilitates things like:\n\nEasy insertions or deletions anywhere\nQuickly accessing the first and last elements\nEasy storage in memory since memory doesn’t need to be in one contiguous block\n\nBut search algorithms are limited to stepping through the list until a desired element is found.\nOn the other hand, the heap allows for intelligent searching. Of course heaps aren’t good for everything: for example, accessing the nth element would be easier in an array than in a heap.\nReferences:\nBerlekamp’s algorithm https://en.wikipedia.org/wiki/Berlekamp%27s_algorithm\nRotating doubly-linked list: https://tex.stackexchange.com/questions/242044/add-label-to-a-rotated-doubly-linked-list"
  },
  {
    "objectID": "week1/week1.html#day-2",
    "href": "week1/week1.html#day-2",
    "title": "Week 1: Intro",
    "section": "Day 2",
    "text": "Day 2\nWe’ve moved classrooms to Kresge G1. On 7th of February, and 4th of March we need to be in FXB G12.\nLast time we talked about algorithms like sorting, searching, talking about their time / space complexity.\nAlgorithms need to have finite numbers of instructions.\nDeterministic means there is no randomness.\nWell-definedness means that the computer knows what to do at every step.\nProperties of algorithms include:\n\nFeasibility\nTermination\nDeterministic\n\nThe output is well-defined for every instance\nAt any time, the next step is well-defined\n\nFinite\n\nThe number of steps must be finite\nAt any time point, the required memory must be finite\n\n\nToday let’s discuss about random numbers.\nMotivation could include:\n\nStatistical simulation (Monte Carlo) in statistical methods research.\nThe statistical theories/methods are all based on assumptions. So most theorems state assumptions…\nThe theories can hardly be verified in real world data because\n\n\nthe real data never satisfy the assumption; and (2) the underlying truth is unknown (gold standard)\n\n\nIn simulation, data are created in a well controlled environment (model assumptions) and all truth are known. So the claim in the theorem can be validated and subjected to sensitivity analysis.\n\nWe often use the inverse CDF method to generate random numbers that are distributed a certain way. Or importance sampling. Or metropolis-hastings.\nBut how do we generate uniform random numbers? runif(10).\n\nCould it be just a list somewhere just stored\nIt could be some highly erratic but still deterministic function.\n\nWhy are ZIP CRC Checksums related to randomness? How do those relate to random numbers?\nWhatever we use to produce random numbers, we can perform statistical tests on the output to see if it’s distinguishable from randomness.\nSome good properties of a random number generator:\n\nUniformity\nIndependence\nDiehard tests (They should pass “Diehard” tests, qc-tests for PRNG)\nReplication\nCycle length - should be a long time before numbers repeat\nSpeed (fast)\nMemory usage (little need)\nParallel implementation (desirable for speed)\nCryptographically secure: required for password storage\n\nThe last point refers to the idea that there should be no ‘reversal’; it should not be possible to look at the random numbers generated and tell what the seed is.\nIf we have \\(f: s \\to [0,1]\\), we want to check two things:\n\nIs the output erratic? (Crucial)\nDoes $f^{-1} exist? (Can it be hacked)? (Optional)\n\n\nMid-square method\n\nStart with a 4-digit number \\(z_0\\), then square it. Should be an 8 digit number, and if not pad it.\nDeterministic sequence of numbers $e.g., \\(z_{n+1} = f(z_n)\\). Look at the middle four digits of it. Put the decimal in front.\nRepeat\n\nWe get uniform random number.\nBut this has problems, like two successive zeroes behind the decimal will never disappear.\n\n\nLinear Congruential Generator\nLCG is an algorithm that yields a sequence of pseudo-randomized numbers calculated with a discontinuous piecewise linear equation. They produce a sequence of integers between 0 and m-1 according to \\(z_n = (a * z_{n-1} + c) \\pmod m, \\quad n = 1, 2, ...\\)\nwhere \\(a\\) is the multiplier, \\(c\\) is the increment, and \\(m\\) the modulus. To obtain uniform random numbers on \\((0,1)\\), we take\n\\[u_n = z_n / m.\\]\nGood choices for \\(a\\), \\(c\\), and \\(m\\) are important.\nMarsaglia showed that \\((z_i, z_{i+1})\\) have this non-random structure.\nGood question: Is there a way to determine the number of hyperplanes?\nThe theory behind LCG is relatively easy to understand, and are easily implemented and fast, especially on computer hardware which can provide modulo arithmetic by stoage-bit truncation.\nA linear congruential generator has full period (=cycle length m) if and only if\n\nThe only positive integer that divides both \\(m\\) and \\(c\\) is 1 (the gcd)\nIf \\(q\\) is a prime number that divides \\(m\\), then \\(q\\) divides \\(a-1\\);\nIf 4 divides \\(m\\), then 4 divides \\(a-1\\).\n\nMarin Mersenne\nFor each Mersenne number, it’s prime if and only if it does not divide the corresponding shadow sequence number: \\(S_2 = 4\\), \\(S_n = S_{n-1}^2 - 2\\).\nimport numpy as np\nimport hashlib\nimport matplotlib.pyplot as plt\n\ndef hashing(s):\n    h = hashlib.md5()\n    #h = hashlib.sha256()\n    h.update(str(s).encode(\"utf-8\"))\n    return(h.hexdigest())\n\ndef random_number(seed):\n    temp = hashing(str(seed))\n    x = int(temp,16) / (16**len(temp))\n    return(x)\n\nif __name__==\"__main__\":\n    print(hashing(\"mouse\"))\n    print(hashing(\"house\"))\n    print(random_number(5))\n    # plot n numbers\n    n = 1000\n    x = np.arange(n)\n    y = np.zeros(n)\n    for i in range(n):\n        y[i] = random_number(x[i])\n    plt.plot(x,y,\"+\",color=\"black\")\n    plt.show()\nJohn the Ripper tries to invert the MD5 hashsum.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip"
  }
]